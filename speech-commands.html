/*  pour l'usage de cette interface se referer au ReadMe dans ce depot */
<html>
    <head>
        <title>interface d'entrainement name detector</title>
		
        <link rel="stylesheet" href="https://code.jquery.com/ui/1.13.0/themes/base/jquery-ui.css">
       
   	   <script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
        
        <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.9.0"></script>
		
		<script src="https://code.jquery.com/ui/1.13.0/jquery-ui.min.js"></script>
		
        <style>
.grid {
    border-collapse: collapse;
}
.grid tr td, .grid tr th {
    border: 1px solid black;
}
input {
    width: 150px;
}

.ui-slider-vertical .ui-slider-handle {
    left: -.15em;
    margin-bottom: -.3em;
}
  
.ui-slider .ui-slider-handle {
    width: 0.6em;
    height: 0.6em;
}
.ui-slider-horizontal .ui-slider-handle {
    top: -.15em;
    margin-left: -.3em;
}
.ui-slider-horizontal {
    height: .4em;
    width: 92%;
    margin-left: auto;
    margin-right: auto;
    top: 0.2em;
    margin-bottom: 0.4em;
}

      </style>
    </head>
    <body>
        
        <h2>interface d'entrainement name detector</h2>
        
        <table>
            <tr id="buttons">
				
				
                <td>
                    <button id="add-sample" onclick="addSample(false)">Enregistrer echantillon</button>
                </td>
				<td>
                    <button id="download" onclick="downloadModel()">Telecharger modele</button>
                </td>
                <td>
                    <button id="train" onclick="trainModel()">Entrainer</button>
                </td>
                              
            </tr>
        </table>
        <p id="message"></p>
        <table id="samples" class="grid">
            <tr id="samples-header">
                <th>Le temps de création </th>
                <th>l audio</th>
                <th>la commande à reconnaitre</th>
                <th>La prediction</th>
                <th>La probabilité</th>
                <th>Prediction quantifiée</th>
            </tr>
        </table>
        <datalist id="labels">
            <option value="[OTHER]" label="[OTHER]" />
        </datalist>
        <script>
if (window.location.protocol === 'http:') {
    window.location.replace(
        window.location.href.replace('http:', 'https:'));
}
if (document.domain.split('.').length > 2) {
    var parts = document.domain.split('.');
    while (parts.length > 2)
        parts.shift();
    document.domain = parts.join('.');
}
        </script>
        <script>
/*modele de donnée de base ( données de reconnaissance google ) .*/
var Model_BASE = null;
/* modele d'extration de caracteresitiques */
var caractModel = null;
var model = null;

/*frequence de l'echantillon */
var audio_freq = 16000;

/* pour test*/
var baseLabels = [
    'backward', 'bed', 'bird', 'cat', 'dog', 'down', 'eight',
    'five', 'follow', 'forward', 'four', 'go', 'happy',
    'house', 'learn', 'left', 'marvin', 'nine', 'no',
    'noise', 'off', 'on', 'one', 'right', 'seven', 'sheila',
    'six', 'stop', 'three', 'tree', 'two', 'up', 'visual',
    'wow', 'yes', 'zero', 'unknown'
];

/* etiquettes affecté au modele entraine */
var labels = [];

/* echantillons collecté du microphone */
var samples = [];

/* etiquettes des echantillons */
var modelLabels = null;

/* etiquette echantillon negatif*/
var labelOther = '[OTHER]';

/*1 seconde pour chaque echantillon*/.
var secondPerInput = 0.976;

/* nombre de points de données dans un seule echantillon*/
var audioInputCount = 62 * 256;

/* cepstre de fréquence mel*/

var longAudioSampleMaxCount = 10;
var audioInput = null;
var mfccFrameLen = 12;
var mfccNumFrames = 61;
var msPerMfccFrame = 16;
var numFlattenFeatures = 576;


/* les parametres du modele NNoM*/
var biasShift = 0;
var outputShift = 0;
var modelWeight = null;
var modelBias = null;
var weightDecBit = 0;
var biasDecBit = 0;


var predict ;

// essayer avec les echantillons négatifs en local.
var negativeSampleUrls = [
    'speech-commands/neg.wav' 
];

function setMessage(msg) {
    $('#message').html(msg);
}

function sleep(ms) {
    return new Promise(resolve => {
        setTimeout(resolve, ms);
    });
}

function addSampleToTableRow(sample, index) {
    $('#samples-header').after(
        `<tr class="sample" id="sample_${index}">
<td>${sample.time}</td>
<td>
<button id="play_${index}" onclick="playSample(samples[${index}], this, null, null)">
Play Audio
</button>
<button onclick="removeSample(${index})">Remove</button>
<button onclick="clipSample(${index})"
    ${(sample.isLong || false) ? '' : 'hidden'}>Clip</button>
<div id="slider_${index}"
    ${(sample.isLong || false) ? '' : 'hidden'} ></div>
</td>
<td>
<input list="labels"
    id="label_${index}"
    value="${sample.label || ''}"
    onfocusout="updateLabel(${index}, this.value)"
    ${(sample.isLong || false) ? 'disabled' : ''} />
</td>
<td>${sample.prediction || ''}</td>
<td>${sample.prob || ''}</td>
<td>${sample.prediction2 || ''}</td>
<td>${sample.prob2 || ''}</td>
</tr>`);
    if (sample.isLong) {
        $('#slider_' + index).slider({
            min: 0,
            max: sample.audio.length,
            range: true,
            values: [0, Math.min(sample.audio.length, audioInputCount)],
            stop: (event, ui) => {
                var values = $(event.target).slider('option', 'values');
                playSample(samples[index], event.target, values[0], values[1]);
            },
            slide: (event, ui) => {
                var values = $(event.target).slider('option', 'values');
                if (values[1] - values[0] > audioInputCount) {
                    if (ui.handleIndex === 0) {
                        values[1] = values[0] + audioInputCount;
                    } else {
                        values[0] = values[1] - audioInputCount;
                    }
                    $(event.target).slider('option', 'values', values);
                }
            }
        });
    }
}

function loadSample(key) {
    if (!key.startsWith('ss-'))
        return null;
    obj = JSON.parse(localStorage.getItem(key));
    var binaryStr = atob(obj.feature);
    var bytes = new Uint8Array(binaryStr.length);
    for (var i = 0; i < binaryStr.length; i++) {
        bytes[i] = binaryStr.charCodeAt(i);
    }
    obj.feature = new Float32Array(bytes.buffer);
    if (obj.mfcc) {
        var mfccBinaryStr = atob(obj.mfcc);
        var mfccBytes = new Uint8Array(mfccBinaryStr.length);
        for (var i = 0; i < mfccBinaryStr.length; i++) {
            mfccBytes[i] = mfccBinaryStr.charCodeAt(i);
        }
        obj.mfcc = new Float32Array(mfccBytes.buffer);
    }
    return obj;
}

function saveSample(sample) {
    var feature = btoa(String.fromCharCode(
        ...new Uint8Array(sample.feature.buffer)));
    var obj = {
        time: sample.time,
        label: sample.label,
        isoTime: sample.isoTime,
        feature
    };
    if (sample.mfcc) {
        obj['mfcc'] = btoa(String.fromCharCode(
            ...new Uint8Array(sample.mfcc.buffer)));
    }
    localStorage.setItem(`ss-${sample.isoTime}`,
        JSON.stringify(obj));
}

function usefulSamples() {
    return samples.filter(x => !(x.removed || false) && x.label);
}

function refreshLabels() {
    var l = {};
    usefulSamples().forEach(x => {
        if (x.label !== labelOther)
            l[x.label] = 1;
    });
    labels = Object.keys(l);
    labels.push(labelOther);
    var ee = labels.map(x => `<option value="${x}" label="${x}"/>`);
    $('#labels').html(ee.join(''));
}

function updateLabel(index, label) {
    if (!label)
        return;
    samples[index]['label'] = label;
    refreshLabels();
    saveSample(samples[index]);
}
/* suppripmer echantillon */
function removeSample(index) {
    $(`#sample_${index}`).remove();
    samples[index]['removed'] = true;
    refreshLabels();
    localStorage.removeItem(`ss-${samples[index].isoTime}`);
}

/* calcul et met à jour les prédictions */
function updatePrediction(sample) {
    var modelInput = null;
    if (!sample.mfcc) {
        modelInput = audioToMfcc(sample.audio);
        sample['mfcc'] = modelInput;
    } else {
        modelInput = sample.mfcc;
    }
    if (modelInput.constructor === Float32Array &&
        modelInput.length > mfccNumFrames * mfccFrameLen) {
        if (!model) {
            return;
        }
        var pred = batchPredict(/*cutoff=*/0.3, /*key=*/'', modelInput)[2];
        var words = [];
        pred.forEach(x => {
            if (words.length === 0) {
                words.push(x);
            } else if (x.note !== words[words.length - 1].note) {
                words.push(x);
            } else if (x.prob > words[words.length - 1].prob) {
                words[words.length - 1] = x;
            }
        });
        sample['prediction'] = words
            .map(x => {
                var i = samples.length;
                var begin = Math.round(x.start * audioInputCount / secondPerInput);
                var end = begin + audioInputCount;
                return `
<button onclick="$('#slider_${i}').slider('option', 'values', [${begin}, ${end}]); playSample(samples[${i}], null, ${begin}, ${end});">
${x.note} (${Math.round(x.start * 100) / 100}s ${Math.round(x.prob * 100) / 100}p)
</button>`;
            })
            .join('');
        return;
    }
    var inputTensor = tf.tensor4d(
        modelInput.constructor === Float32Array
            ? modelInput
            : [modelInput],
        [1, mfccNumFrames, mfccFrameLen, 1]);
    var featureTensor = caractModel.predict(inputTensor);
    var feature = featureTensor.dataSync();
    sample['feature'] = feature;
    if (!model) {
        tf.dispose([inputTensor, featureTensor]);
        return;
    }
    var resultTensor = model.predict(featureTensor);
    var result = resultTensor.dataSync();
    var label = -1, prob = 0;
    for (var i = 0; i < result.length; i++) {
        if (result[i] > prob) {
            label = i;
            prob = result[i];
        }
    }
    sample['prediction'] = modelLabels[label];
    sample['prob'] = Math.round(prob * 100) / 100.0;
    if (sample.audio) {
        var result2 = predict(audioInput);
        sample['prediction2'] = modelLabels[Math.floor(result2 / 1000)];
        sample['prob2'] = (result2 % 1000) / 100;
    }
    tf.dispose([inputTensor, featureTensor, resultTensor]);
}


async function playSample(sample, btn, begin, end) {
    if (btn)
        btn.disabled = true;
    setMessage(`Playing audio sample created at ${sample.time}.`);
    var context = new AudioContext({audio_freq: audio_freq});
    var audio = sample.audio;
    if (begin !== null && end !== null) {
        audio = audio.slice(begin, end);
    }
    var audioBuffer = context.createBuffer(
        1, audio.length, audio_freq);
    var audioData = audioBuffer.getChannelData(0);
    audioData.set(audio);
    var source = context.createBufferSource();
    source.buffer = audioBuffer;
    source.connect(context.destination);
    source.start();
    await sleep(audio.length / audio_freq * 1000 + 50);
    await context.close();
    if (btn)
        btn.disabled = false;
}




var stopRecordingFn = null;

async function addSample(isLong) {
    if (isLong && stopRecordingFn !== null) {
        $('#record-sample').prop('disabled', true);
        // Not sure why this is needed to show button as disabled.
        await sleep(50);
        stopRecordingFn();
        stopRecordingFn = null;
        return;
    }

    if (!isLong)
        $('#add-sample').prop('disabled', true);
    try {
        var stream = await navigator.mediaDevices.getUserMedia({
            audio: true, video: false
        });
    } catch (exception) {
        setMessage('Failed to record audio.');
    }
    var context = new AudioContext({audio_freq: audio_freq});
    var source = context.createMediaStreamSource(stream);
    var processor = context.createScriptProcessor(512, 1, 1);
    var audioDataLen = 0;
    var audioData = new Float32Array(audioInputCount * longAudioSampleMaxCount);
    source.connect(processor);
    processor.connect(context.destination);
    var resolveFn = null;
    var promise = new Promise(resolve => {
        if (isLong)
            stopRecordingFn = resolve;
        else
            resolveFn = resolve;
    });
    // Skip the noise in initial recording.
    await sleep(100);
    var started = false;
    processor.onaudioprocess = e => {
        if (!started) {
            setMessage('Say your speech command now.');
            if (isLong)
                $('#record-sample').text('Stop Recording');
            started = true;
        }
        var chunk = e.inputBuffer.getChannelData(0);
        if (isLong) {
            if (audioDataLen + chunk.length > longAudioSampleMaxCount * audioInputCount) {
                if (stopRecordingFn !== null) {
                    stopRecordingFn();
                    stopRecordingFn = null;
                }
                return;
            }
        } else {
            if (audioDataLen + chunk.length > audioInputCount) {
                if (resolveFn !== null) {
                    $('#record-sample').prop('disabled', true);
                    resolveFn();
                    resolveFn = null;
                }
                return;
            }
        }
        if (audioData.length >= audioDataLen + chunk.length) {
            audioData.set(chunk, audioDataLen);
            audioDataLen += chunk.length;
        }
    };
    await promise;
    stream.getAudioTracks().forEach(track => track.stop());
    await context.close();
    if (isLong)
        $('#record-sample').text('Record Audio');
    else
        $('#add-sample').prop('disabled', false);
    if (audioDataLen < audioInputCount) {
        setMessage('Audio sample is too short.');
        $('#record-sample').prop('disabled', false);
        return;
    }
    audioData = audioData.slice(0, audioDataLen);
    var sample = {
        time: new Date().toLocaleString(),
        isoTime: new Date().toISOString(),
        audio: audioData,
        isLong: isLong
    };
    updatePrediction(sample);
    addSampleToTableRow(sample, samples.length);
    samples.push(sample);
    $('#record-sample').prop('disabled', false);
    setMessage('Done. Review the audio sample and add label.');
}

function clipSample(index) {
    var audio = samples[index].audio;
    var offset = $('#slider_' + index).slider('option', 'values');
    if (offset[1] - offset[0] >= audioInputCount) {
        offset[1] = offset[0] + audioInputCount;
        audio = audio.slice(offset[0], offset[1]);
    } else {
        audio = new Float32Array(audioInputCount);
        audio.set(samples[index].audio.slice(offset[0], offset[1]));
    }
    var sample = {
        time: new Date().toLocaleString(),
        isoTime: new Date().toISOString(),
        audio: audio
    };
    updatePrediction(sample);
    addSampleToTableRow(sample, samples.length);
    samples.push(sample);
    setMessage('Done. Review the audio sample and add label.');
}

async function loadNegativeSamples() {
    var context = new AudioContext({audio_freq: audio_freq});
    for (var i = 0; i < negativeSampleUrls.length; i++) {
        var resp = await $.ajax({
            url: negativeSampleUrls[i],
            xhrFields: {responseType: 'blob'},   
            dataType: 'binary'
        });
        var arrayBuffer = await resp.arrayBuffer();
        var audioBuffer = await context.decodeAudioData(arrayBuffer);
        audioBuffer = audioBuffer.getChannelData(0);
        for (var j = 0;
             j + audioInputCount <= audioBuffer.length;
             j += audioInputCount) {
            var audioData = new Float32Array(audioInputCount);
            audioData.set(
                audioBuffer.slice(j, j + audioInputCount));
            var sample = {
                audio: audioData,
                label: labelOther
            };
            updatePrediction(sample);
            sample.audio = null;
            sample.mfcc = null;
            samples.push(sample);
        }
    }
    await context.close();
}

function shuffle(array) {
    for (var i = array.length - 1; i > 0; i--) {
        var j = Math.floor(Math.random() * (i + 1));
        [array[i], array[j]] = [array[j], array[i]];
    }
}

function convertToX4Q7Weights(weights) {
    var num_features = numFlattenFeatures;
    var num_labels = weights.length / num_features;
    var t1 = tf.tensor2d(weights, [num_features, num_labels]);
    var t2 = t1.transpose();
    var weights = t2.dataSync();
    var new_weights = [...weights];
    var counter = 0;
    for (var i = 0; i < Math.floor(num_labels / 4); i++) {
        var row_base = 4 * i;
        for (var j = 0; j < Math.floor(num_features / 4); j++) {
            // for each 4 entries
            var column_base = 4 * j;
            new_weights[counter] = weights[row_base * num_features + column_base];
            new_weights[counter + 1] = weights[(row_base + 1) * num_features + column_base];
            new_weights[counter + 2] = weights[row_base * num_features + column_base + 2];
            new_weights[counter + 3] = weights[(row_base + 1) * num_features + column_base + 2];
            new_weights[counter + 4] = weights[(row_base + 2) * num_features + column_base];
            new_weights[counter + 5] = weights[(row_base + 3) * num_features + column_base];
            new_weights[counter + 6] = weights[(row_base + 2) * num_features + column_base + 2];
            new_weights[counter + 7] = weights[(row_base + 3) * num_features + column_base + 2];
            new_weights[counter + 8] = weights[row_base * num_features + column_base + 1];
            new_weights[counter + 9] = weights[(row_base + 1) * num_features + column_base + 1];
            new_weights[counter + 10] = weights[row_base * num_features + column_base + 3];
            new_weights[counter + 11] = weights[(row_base + 1) * num_features + column_base + 3];
            new_weights[counter + 12] = weights[(row_base + 2) * num_features + column_base + 1];
            new_weights[counter + 13] = weights[(row_base + 3) * num_features + column_base + 1];
            new_weights[counter + 14] = weights[(row_base + 2) * num_features + column_base + 3];
            new_weights[counter + 15] = weights[(row_base + 3) * num_features + column_base + 3];
            counter = counter + 16;
        }
        // the remaining ones are in order
        for (var j = num_features - num_features % 4; j < num_features; j++) {
            new_weights[counter] = weights[row_base * num_features + j];
            new_weights[counter + 1] = weights[(row_base + 1) * num_features + j];
            new_weights[counter + 2] = weights[(row_base + 2) * num_features + j];
            new_weights[counter + 3] = weights[(row_base + 3) * num_features + j];
            counter = counter + 4;
        }
    }
    tf.dispose([t1, t2]);
    return new_weights;
}

function quantize(weight, decBit) {
    var maxVal = Math.max(Math.max(...weight), Math.abs(Math.min(...weight)));
    decBit = decBit || (7 - Math.ceil(Math.log2(maxVal)));
    var factor = Math.pow(2, decBit);
    for (var i = 0; i < weight.length; i++) {
        weight[i] = Math.min(127, Math.round(weight[i] * factor));
    }
    return decBit;
}

function initQuantizedModel(weights) {
    if (modelWeight === null) {
        modelWeight = _malloc(numFlattenFeatures * baseLabels.length);
    }
    if (modelBias === null) {
        modelBias = _malloc(baseLabels.length);
    }
    var weight = [...weights[0].val.dataSync()];
    weightDecBit = quantize(weight);
    weight = convertToX4Q7Weights(weight);
    var bias = [...weights[1].val.dataSync()];
    biasDecBit = quantize(bias);
    biasShift = 3 + weightDecBit - biasDecBit - 1;
    outputShift = 4 + weightDecBit - 2;
    for (var i = 0; i < weight.length; i++) {
        setValue(modelWeight + i, weight[i], 'i8');
    }
    for (var i = 0; i < bias.length; i++) {
        setValue(modelBias + i, bias[i], 'i8');
    }
    initModel(bias.length, modelWeight, weightDecBit, modelBias,
        biasDecBit, biasShift, outputShift);
}

async function trainModel() {
    var nonOtherSamples = usefulSamples().filter(x => x.label !== labelOther);
   
    $('#train').prop('disabled', true);
    if (!model) {
        setMessage('Initializing sample data.');
        await loadNegativeSamples();
    } else {
        model.dispose();
    }
    setMessage('Starting training.');
    var otherSamples = usefulSamples().filter(
        x => x.label === labelOther && x.time);
    if (otherSamples.length < nonOtherSamples.length * 3) {
        var n = nonOtherSamples.length * 3 - otherSamples.length;
        var sysOtherSamples = usefulSamples().filter(
            x => x.label === labelOther && !x.time);
        shuffle(sysOtherSamples);
        otherSamples = otherSamples.concat(
            sysOtherSamples.slice(0, n));
    }
    var ss = nonOtherSamples.concat(otherSamples);
    modelLabels = [...labels];
    var x = ss.map(s => s.feature);
    x = tf.tensor2d(x, [ss.length, ss[0].feature.length]);
    var y = ss.map(s => labels.indexOf(s.label));
    y = tf.oneHot(y, labels.length);
    model = tf.sequential();
    model.add(tf.layers.dense({inputShape: [numFlattenFeatures], units: labels.length}));
    model.add(tf.layers.softmax());
    model.compile({
        optimizer: tf.train.adam(),
        loss: 'categoricalCrossentropy',
        metrics: ['accuracy']
    });
    var epochs = 20;
    var currentEpoch = 1;
    var info = await model.fit(x, y, {
        epochs,
        batchSize: 16,
        callbacks: {
            onBatchEnd: (batch, logs) => {
                if (batch === 0) {
                    setMessage(`Epoch ${currentEpoch} out of ${epochs}.`);
                    currentEpoch++;
                }
            }
        }
    });
    var finalAccuracy = info.history.acc[epochs - 1].toFixed(4);
    tf.dispose([x, y]);
    initQuantizedModel(model.layers[0].weights);
    setMessage(`Training accuracy ${finalAccuracy}.`);
    $('#train').prop('disabled', false);
}

function charCode(b) {
    b = b < 0 ? b + 256 : b;
    return String.fromCharCode(b);
}

function downloadModel() {
    $('#download').prop('disabled', true);
    var modelData = '';
    modelData += charCode(modelLabels.length);
    modelData += charCode(weightDecBit);
    modelData += charCode(biasDecBit);
    modelData += charCode(biasShift);
    modelData += charCode(outputShift);
    var weightLen = numFlattenFeatures * modelLabels.length;
    for (var i = 0; i < weightLen; i++) {
        modelData += charCode(getValue(modelWeight + i, 'i8'));
    }
    for (var i = 0; i < modelLabels.length; i++) {
        modelData += charCode(getValue(modelBias + i, 'i8'));
    }
    modelData = btoa(modelData);
    var text = `import speech_commands as sp
from ubinascii import a2b_base64, b2a_base64

data = a2b_base64('${modelData}')
sp.init(data)
labels = ${JSON.stringify(modelLabels)}
feature = bytearray(732)

def predict(audio):
    result = sp.predict(audio, 0, 0)
    return (labels[result // 1000], result % 1000)

def snapshot():
    global feature
    sp.export_mfcc(feature)

def save(label):
    with open('samples.txt', 'ab') as f:
        f.write(b'{"label": "')
        f.write(label.encode())
        f.write(b'", "mfcc": "')
        f.write(b2a_base64(feature)[:-1])
        f.write(b'"},\\n')
`;
    var blob = new Blob([text], {type: 'text/plain;charset=utf-8'});
    var url = URL.createObjectURL(blob);
    var a = $(`<a download="speech_model.py">Click to download speech_model.py.</a>`);
    a.attr('href', url);
    setMessage('');
    $('#message').append(a);
    $('#download').prop('disabled', false);
}

function clearCache() {
    $('#clear-cache').prop('disabled', true);
    [...Object.keys(localStorage)].forEach(key => {
        if (!key.startsWith('ss-'))
            return;
        localStorage.removeItem(key);
    });
    $('#clear-cache').prop('disabled', false);
}

$('#file').change(e => {
    var reader = new FileReader();
    reader.onload = e2 => {
        var content = e2.target.result.trim();
        if (content.endsWith(','))
            content = content.slice(0, -1);
        var deviceSamples = JSON.parse('[' + content + ']');
        loadSamplesFromDevice(deviceSamples);
        setMessage(`Loaded ${deviceSamples.length} samples.`);
    };
    reader.readAsText(e.target.files[0], 'UTF-8');
});

function batchPredict(cutoff, key, mfcc) {
    var frameLen = mfccFrameLen;
    var numFramesPerInput = mfccNumFrames;
    var numFramesPerStep = 4;
    var secondPerStep = 0.064;
    var prediction = [];
    for (let step = 0; step < Math.floor(numFramesPerInput / numFramesPerStep); step++) {
        var offset = frameLen * numFramesPerStep * step;
        var numInput = Math.floor((mfcc.length - offset) / numFramesPerInput / frameLen);
        if (numInput === 0)
            break;
        var input = new Float32Array(mfcc.buffer, 4 * offset,
            numInput * numFramesPerInput * frameLen);
        var inputTensor = tf.tensor4d(input, [numInput, numFramesPerInput, frameLen, 1]);
        var featureTensor = caractModel.predict(inputTensor);
        var resultTensor = model.predict(featureTensor);
        var result = resultTensor.dataSync();
        for (let i = 0; i * modelLabels.length < result.length; i++) {
            var maxProb = 0.0;
            var maxIndex = 0;
            for (let j = 0; j < modelLabels.length; j++) {
                var prob = result[i * modelLabels.length + j];
                if (prob > maxProb) {
                    maxProb = prob;
                    maxIndex = j;
                }
            }
            if (maxProb > cutoff && maxIndex !== modelLabels.length - 1) {
                var time = i * secondPerInput + step * secondPerStep;
                var offset = (i * numFramesPerInput + step * numFramesPerStep) * frameLen * 4;
                prediction.push({
                    start: time,
                    end: time + secondPerInput,
                    note: modelLabels[maxIndex],
                    prob: maxProb,
                    mfcc: new Float32Array(mfcc.buffer, offset, numFramesPerInput * frameLen)
                });
            }
        }
        tf.dispose([inputTensor, featureTensor, resultTensor]);
    }
    prediction.sort((a, b) => a.start - b.start);
    return ['annotate', key, prediction];
}

function importSamples(annotations) {
    annotations.forEach(sample => {
        for (let i = 0; i < samples.length; i++) {
            var s = samples[i];
            if (s.videoId && s.start && s.videoId === sample.videoId &&
                s.start === sample.start) {
                return;
            }
        }
        updatePrediction(sample);
        sample['time'] = new Date().toLocaleString();
        sample['isoTime'] = new Date().toISOString();
        addSampleToTableRow(sample, samples.length);
        $(`#play_${samples.length}`).prop('disabled', true);
        $(`#label_${samples.length}`).prop('disabled', true);
        samples.push(sample);
        saveSample(sample);
    });
}

function handleMessage(e) {
    var req = e.data;
    if (req[0] === 'predict') {
        if (!model)
            return;
        e.source.postMessage(
            batchPredict(req[1], req[2], req[3]),
            e.origin);
    } else if (req[0] === 'import') {
        importSamples(req[1]);
    }
}

(async () => {
    Model_BASE = await tf.loadLayersModel('speech-commands/model.json');
    caractModel = tf.sequential({
       layers: Model_BASE.layers.slice(
           0, Model_BASE.layers.length - 2)
    });
    caractModel.compile({
        optimizer: tf.train.adam(),
        loss: 'categoricalCrossentropy',
        metrics: ['accuracy']
    });
    loadSamplesFromStorage();
    window.addEventListener("message", handleMessage);
})();
        </script>
    </body>
</html>
